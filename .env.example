# AI Utilities Environment Configuration
# Copy this file to .env and fill in your actual values

# ===== PRIMARY PROVIDER (for single-provider use) =====
AI_API_KEY=sk-your-openai-key-here
AI_PROVIDER=openai
AI_BASE_URL=https://api.openai.com/v1

# ===== MULTI-PROVIDER CONFIGURATION =====
# Individual provider keys (needed for testing, multi-provider scenarios)
OPENAI_API_KEY=your-openai-key-here
GROQ_API_KEY=your-groq-key-here
TOGETHER_API_KEY=your-together-key-here
OPENROUTER_API_KEY=your-openrouter-key-here

# Local provider configurations
TEXT_GENERATION_WEBUI_API_KEY=your-webui-key-here  # optional
TEXT_GENERATION_WEBUI_BASE_URL=http://localhost:5000/v1
FASTCHAT_API_KEY=your-fastchat-key-here  # optional
FASTCHAT_BASE_URL=http://localhost:8000/v1

# ===== USAGE EXAMPLES =====

# Basic OpenAI usage (uses primary provider above):
#   from ai_utilities import AiClient
#   client = AiClient()
#   response = client.ask("Hello")

# Groq usage (explicit provider):
#   client = AiClient(provider="groq", model="llama3-70b-8192")

# Local LM Studio usage:
#   client = AiClient(
#       provider="openai_compatible",
#       base_url="http://localhost:1234/v1",
#       api_key="lm-studio",
#       model="your-local-model"
#   )
