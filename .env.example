# AI Utilities Environment Configuration
# Copy this file to .env and fill in your actual values

# ===== OPTION 1: PRIMARY PROVIDER (Simple Setup) =====
# Choose ONE provider below and uncomment:

# OpenAI
# AI_API_KEY=sk-your-openai-key-here
# AI_PROVIDER=openai
# AI_MODEL=gpt-3.5-turbo
# AI_BASE_URL=https://api.openai.com/v1

# Groq
# AI_API_KEY=gsk-your-groq-key-here
# AI_PROVIDER=groq
# AI_MODEL=llama3-70b-8192
# AI_BASE_URL=https://api.groq.com/openai/v1

# Together AI
# AI_API_KEY=tgp-your-together-key-here
# AI_PROVIDER=together
# AI_MODEL=meta-llama/Llama-3-8b-chat-hf
# AI_BASE_URL=https://api.together.xyz/v1

# OpenRouter
# AI_API_KEY=sk-or-v1-your-openrouter-key-here
# AI_PROVIDER=openrouter
# AI_MODEL=meta-llama/llama-3-8b-instruct:free
# AI_BASE_URL=https://openrouter.ai/api/v1

# ===== OPTION 2: MULTI-PROVIDER (Advanced Setup) =====
# Use individual keys for explicit provider selection
# OPENAI_API_KEY=your-openai-key-here
# GROQ_API_KEY=your-groq-key-here
# TOGETHER_API_KEY=your-together-key-here
# OPENROUTER_API_KEY=your-openrouter-key-here

# ===== LOCAL PROVIDERS (work with both options above) =====
# Local providers require explicit model selection - no defaults available
# Uncomment base URLs for local servers (no API keys needed):
# TEXT_GENERATION_WEBUI_BASE_URL=http://localhost:5000/v1
# FASTCHAT_BASE_URL=http://localhost:8000/v1
# OLLAMA_BASE_URL=http://localhost:11434/v1
# AI_MODEL=llama3  # REQUIRED: Specify your local model name